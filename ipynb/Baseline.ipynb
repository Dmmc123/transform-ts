{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sktime.performance_metrics.forecasting import MeanSquaredError, MeanAbsolutePercentageError\n",
    "from sktime.forecasting.fbprophet import Prophet\n",
    "from sktime.forecasting.sarimax import SARIMAX\n",
    "from sktime.forecasting.varmax import VARMAX\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/TSLA.csv\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df.set_index(\"Date\", inplace=True)\n",
    "train_df, test_df = train_test_split(df, test_size=90, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baselines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_metrics(y_hat: pd.Series, y_true: pd.Series) -> dict[str, float]:\n",
    "    rmse = MeanSquaredError()\n",
    "    mape = MeanAbsolutePercentageError()\n",
    "    days_desc = {7: \"weekly\", 30: \"monthly\", 90: \"quarterly\"}\n",
    "    metrics = {}\n",
    "    for day_id in days_desc:\n",
    "        interval_rmse = rmse(y_hat[:day_id], y_true[:day_id], square_root=True)\n",
    "        interval_mape = mape(y_hat[:day_id], y_true[:day_id])\n",
    "        metrics[days_desc[day_id]] = {\"RMSE\": interval_rmse, \"MAPE\": interval_mape}\n",
    "    return metrics\n",
    "\n",
    "metrics = {}\n",
    "targets = test_df[\"Close\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Walk"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "avg_vol = train_df[\"Close\"].diff().abs().mean()\n",
    "walks = [train_df[\"Close\"].values[-1]]\n",
    "for _ in range(90):\n",
    "    sign = random.choice([-1, 1])\n",
    "    walks.append(walks[-1] + sign * avg_vol)\n",
    "walks = pd.Series(walks[1:])\n",
    "walks.index = targets.index\n",
    "print(get_metrics(y_hat=walks, y_true=targets))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### VARMAX"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "varmax = VARMAX(maxiter=10)\n",
    "varmax.fit(y=train_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = varmax.predict(fh=list(range(1, len(test_df)+1)))[\"Close\"]\n",
    "metrics[\"varmax\"] = {\n",
    "    \"series\": preds,\n",
    "    \"metrics\": get_metrics(y_hat=preds, y_true=targets)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Prophet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prophet = Prophet(\n",
    "    freq=\"D\",\n",
    "    n_changepoints=int(len(train_df) / 12),\n",
    "    add_country_holidays={\"country_name\": \"USA\"},\n",
    "    yearly_seasonality=True\n",
    ")\n",
    "prophet.fit(train_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = prophet.predict(fh=list(range(1, len(test_df)+1)))[\"Close\"]\n",
    "metrics[\"prophet\"] = {\n",
    "    \"series\": preds,\n",
    "    \"metrics\": get_metrics(y_hat=preds, y_true=targets)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### ETS"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ets = AutoETS(auto=True)\n",
    "ets.fit(y=train_df)\n",
    "preds = ets.predict(fh=list(range(1, len(test_df)+1)))[\"Close\"]\n",
    "metrics[\"ets\"] = {\n",
    "    \"series\": preds,\n",
    "    \"metrics\": get_metrics(y_hat=preds, y_true=targets)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SARIMAX"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sarimax = SARIMAX(order=(5, 0, 5))\n",
    "sarimax.fit(y=train_df)\n",
    "preds = sarimax.predict(fh=list(range(1, len(test_df)+1)))[\"Close\"]\n",
    "metrics[\"sarimax\"] = {\n",
    "    \"series\": preds,\n",
    "    \"metrics\": get_metrics(y_hat=preds, y_true=targets)\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### DeepAR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import DeepAR, TimeSeriesDataSet\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, MultivariateNormalDistributionLoss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"time_idx\"] = (df.index - df.index.min()).days\n",
    "df[\"group\"] = \"TSLA\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the parameters for the TimeSeriesDataSet\n",
    "max_prediction_length = 90\n",
    "max_encoder_length = 120\n",
    "training_cutoff = 1000\n",
    "\n",
    "cols = list(df.columns)\n",
    "_ = cols.pop(3)\n",
    "\n",
    "# Create the TimeSeriesDataSet\n",
    "training = TimeSeriesDataSet(\n",
    "    df[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"Close\",\n",
    "    group_ids=[\"group\"],\n",
    "    min_encoder_length=max_encoder_length,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=max_prediction_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[],\n",
    "    time_varying_known_reals=[\"time_idx\"] + cols[:-2],  # include other known features here\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\"Close\"],  # include other unknown features here\n",
    "    target_normalizer=GroupNormalizer(groups=[\"group\"], transformation=\"softplus\"),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "validation = TimeSeriesDataSet.from_dataset(training, df, predict=True, stop_randomization=True)\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=16, num_workers=0, batch_sampler=\"synchronized\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    max_epochs=200,\n",
    "    accelerator=\"cpu\",\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=50,\n",
    "    enable_checkpointing=True,\n",
    ")\n",
    "\n",
    "net = DeepAR.from_dataset(\n",
    "    training,\n",
    "    learning_rate=1e-2,\n",
    "    log_interval=10,\n",
    "    log_val_interval=1,\n",
    "    hidden_size=30,\n",
    "    rnn_layers=5,\n",
    "    optimizer=\"Adam\",\n",
    "    loss=MultivariateNormalDistributionLoss(),\n",
    ")\n",
    "\n",
    "trainer.fit(net, train_dataloaders=train_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder_data = df.iloc[-210:]\n",
    "encoder_dataset = TimeSeriesDataSet(\n",
    "    encoder_data,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"Close\",\n",
    "    group_ids=[\"group\"],\n",
    "    min_encoder_length=max_encoder_length,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=max_prediction_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[],\n",
    "    time_varying_known_reals=[\"time_idx\"] + cols[:-2],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\"Close\"],\n",
    "    target_normalizer=training.target_normalizer,\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "encoder_dataloader = encoder_dataset.to_dataloader(train=False, batch_size=1, num_workers=0)\n",
    "preds = net.predict(encoder_dataloader, return_x=True, mode=\"prediction\")\n",
    "get_metrics(\n",
    "    y_hat=pd.Series(preds.output[0].tolist()),\n",
    "    y_true=df.iloc[-90:][\"Close\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Temporal Fusion Transformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pytorch_forecasting import TemporalFusionTransformer, QuantileLoss\n",
    "\n",
    "net = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.01,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=2,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    optimizer=\"Ranger\",\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"cpu\",\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    # limit_train_batches=50,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    ")\n",
    "trainer.fit(net, train_dataloaders=train_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = net.predict(encoder_dataloader, return_x=True, mode=\"prediction\")\n",
    "get_metrics(\n",
    "    y_hat=pd.Series(preds.output[0].tolist()),\n",
    "    y_true=df.iloc[-90:][\"Close\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
